{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitDataset(splitRatio):\n",
    "    adver_data = pd.read_csv('binary.csv')\n",
    "    X = adver_data[['gre', 'gpa']].values\n",
    "    Y = adver_data[['admit']].values\n",
    "    trainSize = int(X.shape[0] * splitRatio)\n",
    "    indices = np.random.permutation(X.shape[0])\n",
    "    #indices = np.arange(X.shape[0])\n",
    "    training_idx, test_idx = indices[:trainSize], indices[trainSize:]\n",
    "    trainX, testX = X[training_idx, :], X[test_idx, :]\n",
    "    training_idy, test_idy = indices[:trainSize], indices[trainSize:]\n",
    "    trainY, testY = Y[training_idx, :], Y[test_idx, :]\n",
    "    \n",
    "    means1 = np.mean(trainX, axis=0)\n",
    "    stds1 = np.std(trainX, axis=0)\n",
    "    trainX = (trainX - means1) / stds1\n",
    "    \n",
    "    means = np.mean(testX, axis=0)\n",
    "    stds = np.std(testX, axis=0)\n",
    "    testX = (testX - means) / stds\n",
    "    \n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adver_data = pd.read_csv('binary.csv')\n",
    "X = adver_data[['gre', 'gpa']].values\n",
    "Y = adver_data[['admit']].values\n",
    "trainSize = int(X.shape[0] * 0.67)\n",
    "indices = np.random.permutation(X.shape[0])\n",
    "#indices = np.arange(X.shape[0])\n",
    "training_idx, test_idx = indices[:trainSize], indices[trainSize:]\n",
    "trainX, testX = X[training_idx, :], X[test_idx, :]\n",
    "training_idy, test_idy = indices[:trainSize], indices[trainSize:]\n",
    "trainY, testY = Y[training_idx, :], Y[test_idx, :]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#New complete class, with changes:\n",
    "class Neural_Network(object):\n",
    "    def __init__(self, Lambda=0):        \n",
    "        #Define Hyperparameters\n",
    "        self.inputLayerSize = 2\n",
    "        self.outputLayerSize = 1\n",
    "        self.hiddenLayerSize = 3\n",
    "        \n",
    "        #Weights (parameters)\n",
    "        self.W1 = np.random.randn(self.inputLayerSize,self.hiddenLayerSize)\n",
    "        self.W2 = np.random.randn(self.hiddenLayerSize,self.outputLayerSize)\n",
    "        \n",
    "        #Regularization Parameter:\n",
    "        self.Lambda = Lambda\n",
    "        \n",
    "    def forward(self, X):\n",
    "        #Propogate inputs though network\n",
    "        self.z2 = np.dot(X, self.W1)\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        self.z3 = np.dot(self.a2, self.W2)\n",
    "        yHat = self.sigmoid(self.z3) \n",
    "        return yHat\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        #Apply sigmoid activation function to scalar, vector, or matrix\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    def sigmoidPrime(self,z):\n",
    "        #Gradient of sigmoid\n",
    "        return np.exp(-z)/((1+np.exp(-z))**2)\n",
    "    \n",
    "    def costFunction(self, X, y):\n",
    "        #Compute cost for given X,y, use weights already stored in class.\n",
    "        self.yHat = self.forward(X)\n",
    "        J = 0.5*sum((y-self.yHat)**2)/X.shape[0] + (self.Lambda/2)*(np.sum(self.W1**2)+np.sum(self.W2**2))\n",
    "        return J\n",
    "        \n",
    "    def costFunctionPrime(self, X, y):\n",
    "        #Compute derivative with respect to W and W2 for a given X and y:\n",
    "        self.yHat = self.forward(X)\n",
    "        \n",
    "        delta3 = np.multiply(-(y-self.yHat), self.sigmoidPrime(self.z3))\n",
    "        #Add gradient of regularization term:\n",
    "        dJdW2 = np.dot(self.a2.T, delta3)/X.shape[0] + self.Lambda*self.W2\n",
    "        \n",
    "        delta2 = np.dot(delta3, self.W2.T)*self.sigmoidPrime(self.z2)\n",
    "        #Add gradient of regularization term:\n",
    "        dJdW1 = np.dot(X.T, delta2)/X.shape[0] + self.Lambda*self.W1\n",
    "        \n",
    "        return dJdW1, dJdW2\n",
    "    \n",
    "    #Helper functions for interacting with other methods/classes\n",
    "    def getParams(self):\n",
    "        #Get W1 and W2 Rolled into vector:\n",
    "        params = np.concatenate((self.W1.ravel(), self.W2.ravel()))\n",
    "        return params\n",
    "    \n",
    "    def setParams(self, params):\n",
    "        #Set W1 and W2 using single parameter vector:\n",
    "        W1_start = 0\n",
    "        W1_end = self.hiddenLayerSize*self.inputLayerSize\n",
    "        self.W1 = np.reshape(params[W1_start:W1_end], \\\n",
    "                             (self.inputLayerSize, self.hiddenLayerSize))\n",
    "        W2_end = W1_end + self.hiddenLayerSize*self.outputLayerSize\n",
    "        self.W2 = np.reshape(params[W1_end:W2_end], \\\n",
    "                             (self.hiddenLayerSize, self.outputLayerSize))\n",
    "        \n",
    "    def computeGradients(self, X, y):\n",
    "        dJdW1, dJdW2 = self.costFunctionPrime(X, y)\n",
    "        return np.concatenate((dJdW1.ravel(), dJdW2.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeNumericalGradient(N, X, y):\n",
    "        paramsInitial = N.getParams()\n",
    "        numgrad = np.zeros(paramsInitial.shape)\n",
    "        perturb = np.zeros(paramsInitial.shape)\n",
    "        e = 1e-4\n",
    "\n",
    "        for p in range(len(paramsInitial)):\n",
    "            #Set perturbation vector\n",
    "            perturb[p] = e\n",
    "            N.setParams(paramsInitial + perturb)\n",
    "            loss2 = N.costFunction(X, y)\n",
    "            \n",
    "            N.setParams(paramsInitial - perturb)\n",
    "            loss1 = N.costFunction(X, y)\n",
    "\n",
    "            #Compute Numerical Gradient\n",
    "            numgrad[p] = (loss2 - loss1) / (2*e)\n",
    "\n",
    "            #Return the value we changed to zero:\n",
    "            perturb[p] = 0\n",
    "            \n",
    "        #Return Params to original value:\n",
    "        N.setParams(paramsInitial)\n",
    "\n",
    "        return numgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1355,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Need to modify trainer class a bit to check testing error during training:\n",
    "class trainer(object):\n",
    "    def __init__(self, N):\n",
    "        #Make Local reference to network:\n",
    "        self.N = N\n",
    "        \n",
    "    def callbackF(self, params):\n",
    "        self.N.setParams(params)\n",
    "        self.J.append(self.N.costFunction(self.X, self.y))\n",
    "        self.testJ.append(self.N.costFunction(self.testX, self.testY))\n",
    "        \n",
    "    def costFunctionWrapper(self, params, X, y):\n",
    "        self.N.setParams(params)\n",
    "        cost = self.N.costFunction(X, y)\n",
    "        grad = self.N.computeGradients(X,y)\n",
    "        \n",
    "        return cost, grad\n",
    "        \n",
    "    def train(self, trainX, trainY, testX, testY):\n",
    "        #Make an internal variable for the callback function:\n",
    "        self.X = trainX\n",
    "        self.y = trainY\n",
    "        \n",
    "        self.testX = testX\n",
    "        self.testY = testY\n",
    "\n",
    "        #Make empty list to store training costs:\n",
    "        self.J = []\n",
    "        self.testJ = []\n",
    "        \n",
    "        params0 = self.N.getParams()\n",
    "\n",
    "        options = {'maxiter': 200, 'disp' : True}\n",
    "        _res = optimize.minimize(self.costFunctionWrapper, params0, jac=True, method='BFGS', \\\n",
    "                                 args=(trainX, trainY), options=options, callback=self.callbackF)\n",
    "\n",
    "        self.N.setParams(_res.x)\n",
    "        self.optimizationResults = _res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1356,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Training Data:\n",
    "#trainX = np.array(([3,5], [5,1], [10,2], [6,1.5]), dtype=float)\n",
    "#trainY = np.array(([75], [82], [93], [70]), dtype=float)\n",
    "\n",
    "#Testing Data:\n",
    "#testX = np.array(([4, 5.5], [4.5,1], [9,2.5], [6, 2]), dtype=float)\n",
    "#testY = np.array(([70], [89], [85], [75]), dtype=float)\n",
    "splitRatio = 0.67\n",
    "\n",
    "trainX, trainY, testX, testY = splitDataset(splitRatio)\n",
    "\n",
    "#Normalize:\n",
    "#trainX = trainX/np.amax(trainX, axis=0)\n",
    "#trainY = trainY/10 #Max test score is 100\n",
    "\n",
    "#Normalize by max of training data:\n",
    "#testX = testX/np.amax(trainX, axis=0)\n",
    "#testY = testY/10 #Max test score is 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1357,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train network with new data:\n",
    "NN = Neural_Network(Lambda=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1358,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make sure our gradients our correct after making changes:\n",
    "numgrad = computeNumericalGradient(NN, trainX, trainY)\n",
    "grad = NN.computeGradients(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0219356129040016e-10"
      ]
     },
     "execution_count": 1359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Should be less than 1e-8:\n",
    "np.linalg.norm(grad-numgrad)/np.linalg.norm(grad+numgrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1360,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = trainer(NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.101710\n",
      "         Iterations: 109\n",
      "         Function evaluations: 112\n",
      "         Gradient evaluations: 112\n"
     ]
    }
   ],
   "source": [
    "T.train(trainX,trainY,testX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Cost')"
      ]
     },
     "execution_count": 1362,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf92020cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(T.J)\n",
    "plt.plot(T.testJ)\n",
    "plt.grid(1)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
